{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import sys\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from models.yolov3 import *\n",
    "from utils.utils import *\n",
    "from utils.parse_yolo_weights import parse_yolo_weights\n",
    "from utils.vis_bbox import vis_bbox\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose config file for this demo\n",
    "cfg_path = '/home/samsung/Downloads/PyTorch_Gaussian_YOLOv3-master/config/gaussian_yolov3_eval.cfg'\n",
    "\n",
    "# Specify checkpoint file which contains the weights of the model you want to use\n",
    "ckpt_path = '/home/samsung/Downloads/PyTorch_Gaussian_YOLOv3-master/gaussian_yolov3_coco.pth' \n",
    "ckpt = '/home/samsung/Downloads/PyTorch_Gaussian_YOLOv3-master/resnet50-11ad3fa6.pth'\n",
    "\n",
    "# Path to the image file fo the demo\n",
    "image_path = '/home/samsung/Downloads/PyTorch_Gaussian_YOLOv3-master/data/gaussian_yolov3/traffic_1.jpg'\n",
    "\n",
    "# Detection threshold\n",
    "detect_thresh = 0.3\n",
    "\n",
    "# Use CPU if gpu < 0 else use GPU\n",
    "gpu = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configration parameters for this demo\n",
    "with open(cfg_path, 'r') as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "model_config = cfg['MODEL']\n",
    "imgsize = cfg['TEST']['IMGSIZE']\n",
    "confthre = cfg['TEST']['CONFTHRE'] \n",
    "nmsthre = cfg['TEST']['NMSTHRE']\n",
    "gaussian = cfg['MODEL']['GAUSSIAN']\n",
    "\n",
    "# if detect_thresh is not specified, the parameter defined in config file is used\n",
    "if detect_thresh:\n",
    "    confthre = detect_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = YOLOv3(model_config)\n",
    "\n",
    "# Load weight from the checkpoint\n",
    "#print(\"loading checkpoint %s\" % (ckpt_path))\n",
    "state = torch.load(ckpt)\n",
    "\n",
    "#Add all weights to an empty dict\n",
    "md_dict = model.state_dict()\n",
    "\n",
    "pretrained_dict={}\n",
    "#for k,v in state.items():\n",
    "#    pretrained_dict[k]=v\n",
    "\n",
    "\n",
    "checkpoint= torch.load(ckpt_path)\n",
    "for k,v in checkpoint.items():\n",
    "    pretrained_dict[k]=v\n",
    "md_dict={k:v for k, v in md_dict.items() if k in pretrained_dict}\n",
    "md_dict.update(pretrained_dict)\n",
    "\n",
    "#Load ImageNet and YOLO weights to model\n",
    "model.load_state_dict(md_dict)\n",
    "\n",
    "model.train()\n",
    "model.eval()\n",
    "\n",
    "if gpu >= 0:\n",
    "    # Send model to GPU\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Preprocess image\n",
    "img_raw = img.copy()[:, :, ::-1].transpose((2, 0, 1))\n",
    "img, info_img = preprocess(img, imgsize, jitter=0)  # info = (h, w, nh, nw, dx, dy)\n",
    "img = np.transpose(img / 255., (2, 0, 1))\n",
    "img = torch.from_numpy(img).float().unsqueeze(0)\n",
    "\n",
    "if gpu >= 0:\n",
    "    # Send model to GPU\n",
    "    img = Variable(img.type(torch.cuda.FloatTensor))\n",
    "else:\n",
    "    img = Variable(img.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(img)\n",
    "    outputs = postprocess(outputs, 80, confthre, nmsthre)\n",
    "\n",
    "if outputs[0] is None:\n",
    "    #Exit out of code with no errors\n",
    "    print(\"No Objects Deteted!!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# Visualize detected bboxes\n",
    "coco_class_names, coco_class_ids, coco_class_colors = get_coco_label_names()\n",
    "\n",
    "bboxes = list()\n",
    "classes = list()\n",
    "scores = list()\n",
    "colors = list()\n",
    "sigmas = list()\n",
    "\n",
    "for output in outputs[0]:\n",
    "    x1, y1, x2, y2, conf, cls_conf, cls_pred = output[:7]\n",
    "    if gaussian:\n",
    "        sigma_x, sigma_y, sigma_w, sigma_h = output[7:]\n",
    "        sigmas.append([sigma_x, sigma_y, sigma_w, sigma_h])\n",
    "\n",
    "    cls_id = coco_class_ids[int(cls_pred)]\n",
    "    box = yolobox2label([y1, x1, y2, x2], info_img)\n",
    "    bboxes.append(box)\n",
    "    classes.append(cls_id)\n",
    "    scores.append(cls_conf * conf)\n",
    "    colors.append(coco_class_colors[int(cls_pred)])\n",
    "    \n",
    "    # image size scale used for sigma visualization\n",
    "    h, w, nh, nw, _, _ = info_img\n",
    "    sigma_scale_img = (w / nw, h / nh)\n",
    "    \n",
    "fig, ax = vis_bbox(\n",
    "    img_raw, bboxes, label=classes, score=scores, label_names=coco_class_names, sigma=sigmas, \n",
    "    sigma_scale_img=sigma_scale_img,\n",
    "    sigma_scale_xy=2., sigma_scale_wh=2.,  # 2-sigma\n",
    "    show_inner_bound=False,  # do not show inner rectangle for simplicity\n",
    "    instance_colors=colors, linewidth=3)\n",
    "\n",
    "fig.savefig('demo.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
